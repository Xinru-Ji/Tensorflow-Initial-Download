{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e22b741b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 梯度下降算法是一种致力于找到函数极值点的算法。\n",
    "# 所谓“学习”便是改进模型参数，以便通过大量训练步骤将损失最小化。\n",
    "# 将梯度下降法应用于寻找损失函数的极值点便构成了依据输入数据的模\n",
    "# 型学习。梯度的输出是一个由若干偏导数构成的向量，它的每个分量对\n",
    "# 应于函数对输入向量的相应分量的偏导。梯度的输出向量表明了在每个\n",
    "# 位置损失函数增长最快的方向，可讲它视为表示了在函数的每个位置向\n",
    "# 哪个方向移动函数值可以增长"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f59a144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 梯度下降的过程中，梯度特别大移动的比较大，那也不一定好。\n",
    "# 它可能来回跳来跳去，就是达不到极值点；太慢的话可能需要\n",
    "# 很长的时间才能到极值点(epochs很大)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ce5d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 如何避免局部的极值点呢？在深度学习中，局部极值点从来都不是\n",
    "# 问题，对随机初始化到处跑点，所以不用担心得到的极值点只是局部极值\n",
    "# 点。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
